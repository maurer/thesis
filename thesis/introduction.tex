\chapter{Introduction}
Poorly or maliciously coded software can cause significant damage.
The bulk of modern software is distributed in binary-only form, for reasons ranging from a desire to keep proprietary information secret to wanting to avoid compilation or interpretation overhead on the client.
Unfortunately, inspecting the behavior of machine code is difficult:
It is undecidable for pathological cases and difficult to approximate in common ones.

Existing tools~\cite{ida, bap, bitblaze, bindead} tend to be designed as a sequence of analyses to perform, with the results of each previous analysis being available to the next.
In this model, the analysis authors manually acquire the inputs for their analysis, determine where in the sequence to run it, and where to put the outputs.
If we consider a graph with nodes representing analyses, and edges representing dependency ordering, this model forms a line.
The line model is essentially an ad-hoc form of LLVM\cite{llvm}'s pass model.
In LLVM's pass model, each pass declares what analyses it depends upon, allowing the LLVM pass manager to ensure the necessary steps are performed and allow a configurable pipeline.
Considering the graph representation again, LLVM's model looks more like a DAG.
Jakstab~\cite{jakstab} takes the approach of running their analyses to a fixed point.
As Jakstab does not explicitly encode dependencies between analysis, the graph of execution dependencies looks like a single cycle.
A natural extension then is to allow the expression of dependencies, as in LLVM, but also cycles, as in Jakstab.
This full graph model of analysis management is what I intend to investigate in my thesis.

% Past work sets the stage for / encourages this
Previous work in program analysis suggests that logic languages can help to structure this problem.
% * Datalog/prolog as a program analysis tool
Datalog has previously been successfully used to analyze programs~\cite{lam2005,brumley2006,alpuente2011,doop1,bddbddb}.
%   * Shows fact-like representation of program properties is feasible
While the ability to write analyses directly in logic language is interesting, of more potential importance to the feasability of this project is that they were able to model both their input and output knowledge as logic language predicates successfully.
A wide variety of properties from aliasing in compiled code~\cite{brumley2006} to security properties such as SQL injectability and cross site scriptability (XSS)~\cite{lam2005} have been modeled as facts in a deductive database, suggesting this as a potential common representation.
Dataflow analyses are also representable~\cite{mcallester2002} in this way.

% * Analysis Integration improved results
As using a logic language to describe the analysis process gives us both a common representation for information and the ability to see which analyses can and should be run when, integration should be easier.
%   * Jakstab
Jakstab~\cite{jakstab} is one example where simply integrating two analyses (value analysis and control flow recovery/disassembly) lead to better results than IDA\cite{ida} for jump resolution.
If both analyses had been specified as logical rules within the same environment, the additional power Jakstab found by integrating them would have come for free.

%   * Compositional May Must
Similarly, \textsc{Smash}~\cite{smash} combined \textsc{Dash}'s~\cite{dash} may and must analyses.
\textsc{Dash}-may-analysis derives facts about procedures stating that if a given property holds on an input, a separate property holds at the output.
\textsc{Dash}-must-analysis derives facts stating that within a given set of inputs, there exists at least one that goes to each of a given set of outputs.
The authors were able to prune a number of search paths via this combination, leading to property checks terminating which previously took too long to be feasible to run.
With a (backwards-chaining\footnote{Goal driven execution, more explanation in \S\ref{sec:bchain}}) representation of may and must analyses separately, their analysis could be derived by adding a relatively small number of rules to describe the yes/no property check fact they introduce.

% External code
Using a fairly common extension of logic language, we can even call out to code not written as logical rules\footnote{We use a system similar to external predicates \S\ref{sec:extpred}}.
This makes it possible to repurpose previously written analyses, or to write new analyses which may not be best represented as rules.
There are still some restrictions on how such code can operate (for example, no preserved state across calls) but taking this approach gives the flexibility to be an integration system.

\begin{inset}
{\bf Thesis statement.}
Co-dependence in binary program analysis can be represented in a logic language that allows for formal reasoning about the derivation of its conclusions and increased modularity of analyses.
\end{inset}

% Roadmap to defending the thesis statement
% * Show the power by
%   * Implementing the integration of several real analyses using the language
%   * Attempting to do so without using circumscription or aggregation, and seeing what happens.
I investigated this approach by designing implementing \sysname, a logic language engine designed for the integration of binary analyses.
I implemented codependent alias analysis, use-after-free detection, and control flow recovery using \sysname.
This implementation provides evidence for the feasibility of using a logic language as an integration layer for cyclically dependent analyses.
For this purpose I invented a novel form of negation, based on circumscription~\cite{circumscription}, which is suited to this particular application (\S~\ref{holmes:sec:circ}).
I define the semantics of the resulting logic language in terms of a Kripke structure (\S~\ref{chap:formal}).
I show that \sysname can implement different sensitivities of alias analysis, and show how this affects practical use-after-free classification (\S~\ref{chap:alias}).
I present a type recovery mechanism for compiled code which would be well suited to a Holmes-based implementation (\S~\ref{chap:bitr}).
I give a methodology for testing patches live, once a Holmes-based system locates a bug (\S~\ref{chap:tachyon}).
I conclude that \sysname does address the problem of co-dependence in program analysis and allow analyses to be specified in a modular fashion(\S~\ref{sec:conc}).
